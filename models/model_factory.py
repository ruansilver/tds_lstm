"""
æ¨¡å‹å·¥å‚ - æ”¯æŒåŠ¨æ€æ¨¡å‹æ³¨å†Œå’Œçµæ´»é…ç½®
æä¾›ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºæ¥å£ï¼Œæ”¯æŒæ‰©å±•æ–°çš„æ¨¡å‹ç±»å‹
"""

import torch.nn as nn
from typing import Dict, Any, Type, List, Optional
import logging
import inspect

from .tds_lstm_model import TDSLSTMModel
from config import Config

logger = logging.getLogger(__name__)


class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ç±»å‹"""
    
    def __init__(self):
        self._models: Dict[str, Type[nn.Module]] = {}
        self._model_configs: Dict[str, Dict[str, Any]] = {}
        self._register_default_models()
    
    def _register_default_models(self):
        """æ³¨å†Œé»˜è®¤æ¨¡å‹"""
        self.register_model('tds_lstm', TDSLSTMModel, {
            'input_size': 16,
            'output_size': 20,
            'encoder_features': 64,
            'decoder_hidden': 64,
            'decoder_layers': 2,
            'rollout_freq': 50,
            'original_sampling_rate': 2000,
            'dropout': 0.2,
            'predict_velocity': False,
        })
    
    def register_model(self, name: str, model_class: Type[nn.Module], default_config: Optional[Dict[str, Any]] = None):
        """
        æ³¨å†Œæ–°çš„æ¨¡å‹ç±»
        
        Args:
            name: æ¨¡å‹åç§°
            model_class: æ¨¡å‹ç±»
            default_config: é»˜è®¤é…ç½®å‚æ•°
        """
        if not issubclass(model_class, nn.Module):
            raise ValueError(f"æ¨¡å‹ç±»å¿…é¡»ç»§æ‰¿è‡ªnn.Module: {model_class}")
        
        self._models[name] = model_class
        self._model_configs[name] = default_config or {}
        logger.info(f"âœ… æ³¨å†Œæ¨¡å‹: {name} -> {model_class.__name__}")
    
    def get_model_class(self, name: str) -> Type[nn.Module]:
        """è·å–æ¨¡å‹ç±»"""
        if name not in self._models:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {name}. å¯ç”¨æ¨¡å‹: {self.list_models()}")
        return self._models[name]
    
    def get_default_config(self, name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çš„é»˜è®¤é…ç½®"""
        return self._model_configs.get(name, {}).copy()
    
    def list_models(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        return list(self._models.keys())
    
    def get_model_info(self, name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        if name not in self._models:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {name}")
        
        model_class = self._models[name]
        signature = inspect.signature(model_class.__init__)
        
        return {
            'name': name,
            'class': model_class.__name__,
            'module': model_class.__module__,
            'parameters': list(signature.parameters.keys())[1:],  # æ’é™¤self
            'default_config': self._model_configs.get(name, {}),
            'docstring': model_class.__doc__
        }


# å…¨å±€æ¨¡å‹æ³¨å†Œè¡¨
_model_registry = ModelRegistry()


class ModelFactory:
    """æ¨¡å‹å·¥å‚ç±» - æä¾›ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºæ¥å£"""
    
    @classmethod
    def register_model(cls, name: str, model_class: Type[nn.Module], default_config: Optional[Dict[str, Any]] = None):
        """æ³¨å†Œæ–°çš„æ¨¡å‹ç±»"""
        _model_registry.register_model(name, model_class, default_config)
    
    @classmethod
    def create_model(
        cls,
        model_name: str = 'tds_lstm',   
        config: Optional[Config] = None,
        **kwargs
    ) -> nn.Module:
        """
        åˆ›å»ºæŒ‡å®šç±»å‹çš„æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            config: é…ç½®å¯¹è±¡
            **kwargs: é¢å¤–çš„æ¨¡å‹å‚æ•°
            
        Returns:
            åˆ›å»ºçš„æ¨¡å‹å®ä¾‹
        """
        # è·å–æ¨¡å‹ç±»
        model_class = _model_registry.get_model_class(model_name)
        
        # å‡†å¤‡æ¨¡å‹å‚æ•°
        model_params = _model_registry.get_default_config(model_name)
        
        # ä»é…ç½®å¯¹è±¡æ›´æ–°å‚æ•°
        if config is not None:
            config_params = cls._extract_config_params(model_name, config)
            model_params.update(config_params)
        
        # è¦†ç›–é¢å¤–å‚æ•°
        model_params.update(kwargs)
        
        # éªŒè¯å‚æ•°
        cls._validate_model_params(model_class, model_params)
        
        # åˆ›å»ºæ¨¡å‹
        try:
            model = model_class(**model_params)
            logger.info(f"âœ… åˆ›å»ºæ¨¡å‹: {model_name} ({model_class.__name__})")
            logger.debug(f"ğŸ“Š æ¨¡å‹å‚æ•°: {model_params}")
            
            # è®°å½•æ¨¡å‹å¤§å°ä¿¡æ¯
            if hasattr(model, 'get_model_size'):
                total_params = model.get_model_size()
                logger.info(f"ğŸ“ æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")
                
            return model
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}")
            logger.error(f"ğŸ” æ¨¡å‹ç±»: {model_class}")
            logger.error(f"ğŸ” å‚æ•°: {model_params}")
            raise
    
    @classmethod
    def _extract_config_params(cls, model_name: str, config: Config) -> Dict[str, Any]:
        """ä»é…ç½®å¯¹è±¡ä¸­æå–æ¨¡å‹å‚æ•°"""
        params = {}
        
        if model_name == 'tds_lstm':
            # TDS-LSTMæ¨¡å‹å‚æ•°æ˜ å°„
            params.update({
                'input_size': config.model.input_size,
                'output_size': config.model.output_size,
                'rollout_freq': getattr(config.model, 'rollout_freq', 50),
                'original_sampling_rate': getattr(config.model, 'original_sampling_rate', 2000),
                'dropout': config.model.dropout,
                'predict_velocity': getattr(config.model, 'predict_velocity', False),
            })
            
            # TDSç¼–ç å™¨é…ç½®
            if hasattr(config.model, 'tds_stages') and config.model.tds_stages:
                params['tds_stages_config'] = config.model.tds_stages
            
            # LSTMè§£ç å™¨é…ç½®
            params['decoder_type'] = getattr(config.model, 'decoder_type', 'sequential_lstm')
            params['decoder_hidden_size'] = getattr(config.model, 'decoder_hidden_size', 128)
            params['decoder_num_layers'] = getattr(config.model, 'decoder_num_layers', 2)
            params['decoder_state_condition'] = getattr(config.model, 'decoder_state_condition', True)
            
        else:
            # é€šç”¨æ¨¡å‹å‚æ•°
            params.update({
                'input_size': getattr(config.model, 'input_size', 16),
                'output_size': getattr(config.model, 'output_size', 20),
                'hidden_size': getattr(config.model, 'hidden_size', 128),
                'num_layers': getattr(config.model, 'num_layers', 2),
                'dropout': getattr(config.model, 'dropout', 0.2),
                'bidirectional': getattr(config.model, 'bidirectional', True),
            })
        
        return params
    
    @classmethod
    def _validate_model_params(cls, model_class: Type[nn.Module], params: Dict[str, Any]):
        """éªŒè¯æ¨¡å‹å‚æ•°"""
        try:
            signature = inspect.signature(model_class.__init__)
            valid_params = set(signature.parameters.keys()) - {'self'}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆå‚æ•°
            invalid_params = set(params.keys()) - valid_params
            if invalid_params:
                logger.warning(f"âš ï¸ å¿½ç•¥æ— æ•ˆå‚æ•°: {invalid_params}")
                # ç§»é™¤æ— æ•ˆå‚æ•°
                for param in invalid_params:
                    params.pop(param, None)
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°
            required_params = [
                name for name, param in signature.parameters.items() 
                if param.default == inspect.Parameter.empty and name != 'self'
            ]
            missing_params = set(required_params) - set(params.keys())
            if missing_params:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_params}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ å‚æ•°éªŒè¯å¤±è´¥: {e}")
    
    @classmethod
    def list_models(cls) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        return _model_registry.list_models()
    
    @classmethod
    def get_model_info(cls, model_name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        return _model_registry.get_model_info(model_name)
    
    @classmethod
    def print_available_models(cls):
        """æ‰“å°æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
        models = cls.list_models()
        logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹æ•°é‡: {len(models)}")
        
        for model_name in models:
            try:
                info = cls.get_model_info(model_name)
                logger.info(f"  ğŸ”§ {model_name}: {info['class']}")
                if info['docstring']:
                    logger.info(f"     ğŸ“ {info['docstring'].strip().split('.')[0]}")
            except Exception as e:
                logger.warning(f"  âŒ {model_name}: ä¿¡æ¯è·å–å¤±è´¥ ({e})")


# ä¾¿æ·å‡½æ•°
def create_model(model_name: str = 'tds_lstm', config: Optional[Config] = None, **kwargs) -> nn.Module:
    """
    ä¾¿æ·çš„æ¨¡å‹åˆ›å»ºå‡½æ•°
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º'tds_lstm'
        config: é…ç½®å¯¹è±¡
        **kwargs: é¢å¤–çš„æ¨¡å‹å‚æ•°
        
    Returns:
        åˆ›å»ºçš„æ¨¡å‹å®ä¾‹
    """
    return ModelFactory.create_model(model_name, config, **kwargs)


def register_model(name: str, model_class: Type[nn.Module], default_config: Optional[Dict[str, Any]] = None):
    """
    æ³¨å†Œæ–°æ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        name: æ¨¡å‹åç§°
        model_class: æ¨¡å‹ç±»
        default_config: é»˜è®¤é…ç½®
    """
    ModelFactory.register_model(name, model_class, default_config)


def list_models() -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹çš„ä¾¿æ·å‡½æ•°"""
    return ModelFactory.list_models()


def get_model_info(model_name: str) -> Dict[str, Any]:
    """è·å–æ¨¡å‹ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    return ModelFactory.get_model_info(model_name)
